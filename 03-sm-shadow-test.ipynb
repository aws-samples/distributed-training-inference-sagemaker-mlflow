{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f33afa",
   "metadata": {},
   "source": [
    "# Validate Your New ML model Performance in Production using SageMaker Shadow Testing\n",
    "Shadow testing in Amazon SageMaker is a unique capability that allows you to evaluate new machine learning models or infrastructure changes by comparing their performance against currently deployed production systems without impacting end users. Shadow Testing is designed to help MLOps engineers and developers catch any potential configuration errors before deploying the model live which could impact users. Another benefit of using Shadow Testing is to evaluate operational metrics such as latency, throughput and error rate against live production traffic to give you a realistic benchmark to work backward from. \n",
    "\n",
    "Shadow Testing helps eliminate weeks of time spent building infrastructure for shadow testing, so you can release models to production faster.\n",
    "\n",
    "## How It Works\n",
    "The process involves two key components:\n",
    "\n",
    "* A production variant that receives and responds to 100% of incoming inference requests\n",
    "* A shadow variant that receives a copy of the requests but doesn't return responses to the caller. You can optionally turn on data capture to save request and/or response to an S3 bucket of your choice.\n",
    "\n",
    "Here's an architecture diagram that depicts Shadow Testing on SageMaker:\n",
    "\n",
    "<!-- ![shadow test diagram](img/shadow-test-diagram.png) -->\n",
    "\n",
    "<img src=\"img/shadow-test-diagram.png\" width=\"800\">\n",
    "\n",
    "## Common Use Cases\n",
    "* You’re considering promoting a new model that has been validated offline to production, but want to evaluate operational performance metrics, such as latency, error rate, and so on, before making this decision.\n",
    "  \n",
    "* You’re considering changes to your serving infrastructure container, such as patching vulnerabilities or upgrading to newer versions, and want to assess the impact of these changes prior to promotion to production.\n",
    "  \n",
    "* You’re considering changing your ML instance and want to evaluate how the new instance would perform with live inference requests.\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\"> \n",
    "<b>Note:</b> SageMaker AI supports a maximum of one shadow variant per endpoint. For an endpoint with a shadow variant, there can be a maximum of one production variant. \n",
    "</div>\n",
    "</br>\n",
    "\n",
    "In this lab, we'll walk you through setting up a Shadow Testing for the Two Tower Retrieval model that we built in the previous labs. You can create a Shadow Test from SageMaker AI Console, or using API calls. We 'll use the API calls so that you understand how the end to end process works. \n",
    "\n",
    "If you missed them please go back and run these labs in order: [00-start-here.ipynb](00-start-here.ipynb), [01-sm-training.ipynb](01-sm-training.ipynb), [02-sm-inference.ipynb](02-sm-inference.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629c1f94",
   "metadata": {},
   "source": [
    "Install additional dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115a4fd-cee3-4772-a851-5776f007c9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install Pillow -q -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26236ee9",
   "metadata": {},
   "source": [
    "Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35982013-711f-41ab-bd03-d5012f9a312a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.local import LocalSession\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import io\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from datetime import datetime\n",
    "from sagemaker import image_uris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b99a1",
   "metadata": {},
   "source": [
    "Retrieve the stored variables from previous labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652ad10-80f2-413a-9541-528e1e125372",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b21ba",
   "metadata": {},
   "source": [
    "Setting up a proper IAM role, a sagemaker session and model URL for a Shadow Testing deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703c66b-c3ea-4f19-a7af-2f731cb3f643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# session = LocalSession() # uncomment for running in local mode.\n",
    "# session.config = {'local': {'local_code': True} } # uncomment for running in local mode.\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "model_data_url = model_serving_data_s3_uri\n",
    "bucket = session.default_bucket()\n",
    "prefix = \"models/shadow-test\"\n",
    "\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b5e79c",
   "metadata": {},
   "source": [
    "Download a copy of the current model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7765360",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {model_data_url} model/prod.tar.gz\n",
    "!aws s3 cp {model_data_url} model/shadow.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ba2e7-4222-4b53-ae8b-348097d5e2be",
   "metadata": {},
   "source": [
    "In the following cell, we are introducing a small latency to the shadow model variant by adding a delay (0.5s) in the inference script. \n",
    "After the change, we'll deploy both models as production and shadow endpoints, and run load tests against these endponts. Finally, we'll observe the performance metrics of each endpoint. We expect the latency metrics for the shadow endpoint to be higher than the production variant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b733e-2eb0-4544-b1bd-5099013df562",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf temp/ && mkdir -p temp && cd temp && tar -xvzf ../model/shadow.tar.gz >/dev/null 2>&1 && cp ../shadow/inference.py code/inference.py && tar -cvzf ../model/shadow.tar.gz . >/dev/null 2>&1 && cd .. && rm -rf temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64b7b5",
   "metadata": {},
   "source": [
    "Uploads these artifacts into separate folders in S3. This step is done to simulate a Shadow and Production variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_model_url = S3Uploader.upload(\n",
    "    local_path=\"model/prod.tar.gz\",\n",
    "    desired_s3_uri=f\"s3://{bucket}/{prefix}\",\n",
    ")\n",
    "shadow_model_url = S3Uploader.upload(\n",
    "    local_path=\"model/shadow.tar.gz\",\n",
    "    desired_s3_uri=f\"s3://{bucket}/{prefix}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ab8a3f",
   "metadata": {},
   "source": [
    "Provide a unique name to the production and shadow models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4631553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_model_name = f\"two-tower-prod-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "shadow_model_name = f\"two-tower-shadow-{datetime.now():%Y-%m-%d-%H-%M-%S}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2594ab",
   "metadata": {},
   "source": [
    "Use SageMaker SDK to retrieve the ECR container image URI for the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='pytorch',\n",
    "    region=boto3.Session().region_name, \n",
    "    version='2.5.1',     # PyTorch version\n",
    "    py_version='py311',  # Python version\n",
    "    image_scope='inference',\n",
    "    instance_type='ml.g4dn.2xlarge' \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798861c9",
   "metadata": {},
   "source": [
    "Once the models are uploaded to S3, we'll use the boto3 client to create production and shadow SageMaker models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6db378",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_model_s3_data_url = f\"s3://{bucket}/{prefix}/prod.tar.gz\"\n",
    "shadow_model_s3_data_url = f\"s3://{bucket}/{prefix}/shadow.tar.gz\"\n",
    "\n",
    "resp = sm.create_model(\n",
    "    ModelName=prod_model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    Containers=[{\"Image\": inference_image_uri, \"ModelDataUrl\": prod_model_s3_data_url, \"Environment\" : {\n",
    "        \"MASTER_ADDR\" : \"localhost\", \n",
    "        \"MASTER_PORT\" : \"12356\", \n",
    "        \"CUDA_VISIBLE_DEVICES\" : \"0\",\n",
    "        \"LOCAL_RANK\" : \"0\",\n",
    "        \"WORLD_SIZE\" : \"1\"\n",
    "    }}],\n",
    ")\n",
    "\n",
    "resp = sm.create_model(\n",
    "    ModelName=shadow_model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    Containers=[{\"Image\": inference_image_uri, \"ModelDataUrl\": shadow_model_s3_data_url, \"Environment\" : {\n",
    "        \"MASTER_ADDR\" : \"localhost\", \n",
    "        \"MASTER_PORT\" : \"12356\", \n",
    "        \"CUDA_VISIBLE_DEVICES\" : \"0\",\n",
    "        \"LOCAL_RANK\" : \"0\",\n",
    "        \"WORLD_SIZE\" : \"1\"\n",
    "    }}],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f30f6",
   "metadata": {},
   "source": [
    "In the following step, we create an endpoint config with the production and shadow variants. The `ProductionVariants` and `ShadowProductionVariants` are of particular interest. Both these variants have ml.g4dn.2xlarge instances and the initial instance count is set to 1. We can provide these information with a single API call `create_endpoint_config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f965128",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_config_name = f\"Shadow-EpConfig-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "production_variant_name = \"production\"\n",
    "shadow_variant_name = \"shadow\"\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=ep_config_name,\n",
    "    ProductionVariants=[\n",
    "    # Type: Array of ProductionVariant (https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ProductionVariant.html) objects\n",
    "      {\n",
    "            \"VariantName\": production_variant_name,\n",
    "            \"ModelName\": prod_model_name,\n",
    "            \"InstanceType\": \"ml.g4dn.2xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "      }\n",
    "    ],\n",
    "     # Type: Array of ShadowProductionVariants \n",
    "    ShadowProductionVariants = [\n",
    "      {\n",
    "        \"VariantName\": shadow_variant_name,  \n",
    "         \"ModelName\": shadow_model_name,\n",
    "         \"InitialInstanceCount\": 1,\n",
    "         \"InitialVariantWeight\": 1,\n",
    "         \"InstanceType\": \"ml.g4dn.2xlarge\" \n",
    "      }\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdcb41a",
   "metadata": {},
   "source": [
    "After the endpoint configuration for production and shadow endpoints are created, we can now proceed with deploying an endpoint with production and shadow variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ecc6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"two-tower-prod-shadow-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "create_endpoint_api_response = sm.create_endpoint(\n",
    "                                    EndpointName=endpoint_name,\n",
    "                                    EndpointConfigName=ep_config_name,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a915c6",
   "metadata": {},
   "source": [
    "We'll wait for the endpoint to be ready. This step should take about 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db1f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "def wait_for_endpoint(client, endpoint_name, timeout_seconds=1200):\n",
    "    \"\"\"\n",
    "    Wait for SageMaker endpoint to be ready\n",
    "    \n",
    "    Args:\n",
    "        client: Boto3 SageMaker client\n",
    "        endpoint_name: Name of the endpoint\n",
    "        timeout_seconds: Maximum time to wait in seconds\n",
    "        \n",
    "    Returns:\n",
    "        True if endpoint is ready, False if timeout occurred\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while time.time() - start_time < timeout_seconds:\n",
    "        response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = response['EndpointStatus']\n",
    "        \n",
    "        if status == 'InService':\n",
    "            return True\n",
    "        \n",
    "        if status == 'Failed':\n",
    "            raise Exception(f\"Endpoint creation failed: {response['FailureReason']}\")\n",
    "            \n",
    "        time.sleep(30)\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for endpoint to be ready\n",
    "is_ready = wait_for_endpoint(sm, endpoint_name)\n",
    "\n",
    "if is_ready:\n",
    "    print(\"Endpoint is ready\")\n",
    "else:\n",
    "    print(\"Endpoint creation timed out\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae00edad",
   "metadata": {},
   "source": [
    "Now that the endpoint is ready, let's begin with some test. In the following code, we will send 1000 requests to the endpoint iteratively. After the call is complete, we'll evaluate the performance metrics for each variant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_endpoint(endpoint_name, wait_interval_sec=0.01, should_raise_exp=False, iterations=1000):\n",
    "    payload = {\"inputs\": [1, 2, 3]}\n",
    "    for i in range(iterations):\n",
    "        response = sm_runtime.invoke_endpoint(EndpointName=endpoint_name, ContentType=\"application/json\", Body=json.dumps(payload))\n",
    "        if i == 0:\n",
    "            response_body = response['Body'].read().decode('utf-8')\n",
    "            print(response_body)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d821299",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = invoke_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b3f9b-8dd7-4f72-ac83-2804ebf7f2ce",
   "metadata": {},
   "source": [
    "# SageMaker AI endpoint invocation metrics\n",
    "By default, when you deploy a model with SageMaker, SageMaker automatically emits important metrics to Cloudwatch that helps you monitor and understand the health of the deployed endpoint. \n",
    "For a complete list of metrics please refer to [this](https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html) link.\n",
    "\n",
    "**Note:** Metrics are available at a 1-minute frequency.\n",
    "\n",
    "The following illustration shows how a SageMaker AI endpoint interacts with the Amazon SageMaker Runtime API. The overall time between sending a request to an endpoint and receiving a response depends on the following three components.\n",
    "\n",
    "* Network latency – the time that it takes between making a request to and receiving a response back from the SageMaker Runtime Runtime API.\n",
    "\n",
    "* Overhead latency – the time that it takes to transport a request to the model container from and transport the response back to the SageMaker Runtime Runtime API.\n",
    "\n",
    "* Model latency – the time that it takes the model container to process the request and return a response.\n",
    "\n",
    "![sagemaker cloudwatch metrics](img/sm-metrics-cloudwatch.png)\n",
    "\n",
    "In the following section, we'll explore some of the key metrics for both the production and shadow variants including the visualization. Similarly, you can access all the metrics relevant the the endpoint in the Amazon Cloudwatch console. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b86ba14",
   "metadata": {},
   "source": [
    "Creating a cloudwatch client to help us bring visualization into the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac876e6d-38d1-410a-8aeb-9bb4944ee0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_client = boto3.client(\"cloudwatch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a191524a-e9f4-425c-b277-b97186bb9898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cw_metrics(endpoint_name):\n",
    "    images = []\n",
    "    stat = \"Average\"\n",
    "    # Container/Model Latency\n",
    "    metrics = [\n",
    "        [ \"AWS/SageMaker\", \"ModelLatency\", \"EndpointName\", endpoint_name, \"VariantName\", \"production\" ],\n",
    "        [ \"AWS/SageMaker\", \"ModelLatency\", \"EndpointName\", endpoint_name, \"VariantName\", \"shadow\" ]]\n",
    "\n",
    "    metric_widget = {\n",
    "        \"metrics\": metrics,\n",
    "        \"view\": \"timeSeries\",\n",
    "        \"stacked\": False,\n",
    "        \"stat\": stat,\n",
    "        \"period\": 5,\n",
    "        \"width\": 1000,\n",
    "        \"height\": 200,\n",
    "    }\n",
    "    response = cw_client.get_metric_widget_image(\n",
    "        MetricWidget=json.dumps(metric_widget)\n",
    "    )\n",
    "    \n",
    "    images.append(Image.open(io.BytesIO(response[\"MetricWidgetImage\"])))\n",
    "\n",
    "    # Container CPU Utilization\n",
    "    metrics = [[ \"/aws/sagemaker/Endpoints\", \"CPUUtilization\", \"EndpointName\", endpoint_name, \"VariantName\", \"production\"],\n",
    "              [ \"/aws/sagemaker/Endpoints\", \"CPUUtilization\", \"EndpointName\", endpoint_name, \"VariantName\", \"shadow\"]]\n",
    "\n",
    "    metric_widget = {\n",
    "        \"metrics\": metrics,\n",
    "        \"view\": \"timeSeries\",\n",
    "        \"stacked\": False,\n",
    "        \"stat\": stat,\n",
    "        \"period\": 5,\n",
    "        \"width\": 1000,\n",
    "        \"height\": 200,\n",
    "    }\n",
    "    response = cw_client.get_metric_widget_image(\n",
    "        MetricWidget=json.dumps(metric_widget)\n",
    "    )\n",
    "\n",
    "    images.append(Image.open(io.BytesIO(response[\"MetricWidgetImage\"])))\n",
    "\n",
    "\n",
    "    # Container Memory Utilization\n",
    "    metrics = [\n",
    "            [ \"/aws/sagemaker/Endpoints\", \"MemoryUtilization\", \"EndpointName\", endpoint_name, \n",
    "             \"VariantName\", \"production\"],\n",
    "            [ \"/aws/sagemaker/Endpoints\", \"MemoryUtilization\", \"EndpointName\", endpoint_name, \n",
    "             \"VariantName\", \"shadow\"]]\n",
    "\n",
    "    metric_widget = {\n",
    "        \"metrics\": metrics,\n",
    "        \"view\": \"timeSeries\",\n",
    "        \"stacked\": False,\n",
    "        \"stat\": stat,\n",
    "        \"period\": 5,\n",
    "        \"width\": 1000,\n",
    "        \"height\": 200,\n",
    "    }\n",
    "    response = cw_client.get_metric_widget_image(\n",
    "        MetricWidget=json.dumps(metric_widget)\n",
    "    )\n",
    "\n",
    "    images.append(Image.open(io.BytesIO(response[\"MetricWidgetImage\"])))\n",
    "\n",
    "    # Invocattions \n",
    "    metrics = [[ \"AWS/SageMaker\", \"Invocations\", \"EndpointName\", endpoint_name, \"VariantName\", \"production\" ],\n",
    "        [ \"AWS/SageMaker\", \"Invocations\", \"EndpointName\", endpoint_name, \"VariantName\", \"shadow\" ]]\n",
    "\n",
    "    metric_widget = {\n",
    "        \"metrics\": metrics,\n",
    "        \"view\": \"timeSeries\",\n",
    "        \"stacked\": False,\n",
    "        \"stat\": \"Sum\",\n",
    "        \"period\": 5,\n",
    "        \"width\": 1000,\n",
    "        \"height\": 200,\n",
    "    }\n",
    "    response = cw_client.get_metric_widget_image(\n",
    "        MetricWidget=json.dumps(metric_widget)\n",
    "    )\n",
    "\n",
    "    images.append(Image.open(io.BytesIO(response[\"MetricWidgetImage\"])))\n",
    "    \n",
    "    for image in images:\n",
    "        image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1374b9f-573d-4898-84ae-7e2307137b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cw_metrics(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0c8fe",
   "metadata": {},
   "source": [
    "# Update to make Shadow Variant primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "promote_ep_config_name = f\"PromoteShadow-EpConfig-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=promote_ep_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": shadow_variant_name,\n",
    "            \"ModelName\": shadow_model_name,\n",
    "            \"InstanceType\": \"ml.g5.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InitialVariantWeight\": 1.0,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(f\"Created EndpointConfig: {create_endpoint_config_response['EndpointConfigArn']}\")\n",
    "\n",
    "update_endpoint_api_response = sm.update_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=promote_ep_config_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eabc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for endpoint to be ready\n",
    "is_ready = wait_for_endpoint(sm, endpoint_name)\n",
    "\n",
    "if is_ready:\n",
    "    print(\"Endpoint is ready\")\n",
    "else:\n",
    "    print(\"Endpoint creation timed out\")\n",
    "    \n",
    "sm.describe_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20417bd-d1fd-424e-8f6e-a8df3d45df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = invoke_endpoint(endpoint_name, iterations=1)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68583391-793e-4d17-aee5-34980d9972c9",
   "metadata": {},
   "source": [
    "### Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6d57c1-bfaf-4807-8df7-cacfa8fa71a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "sm.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=ep_config_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=promote_ep_config_name)\n",
    "sm.delete_model(ModelName=prod_model_name)\n",
    "sm.delete_model(ModelName=shadow_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c52da5-3d23-4c8c-b364-98fb0b361f4d",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "Congratulations! You've complete all the labs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
